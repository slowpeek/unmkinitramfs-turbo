* Files
- unmkinitramfs :: The original tool with =-s, --scan= option added
- unmkinitramfs-turbo :: The improved tool. Runs on =bash=, requires =xxd=

* Scan mode

The =-s, --scan= option makes it not unpack anything, but print calculated
=offset= and =size= of embedded cpio archives. For the last entry only =offset=
is printed. The calculation step is the only non-trivial part in unpacking
initrd. Sample run:

#+begin_example
  > ./unmkinitramfs -s initrd/ubuntu-22.04.4 _
  0 77312
  77312 7208960
  7286272
#+end_example

* Performance boost

Generic initrd contains some uncompressed cpio archives plus the last one
compressed. Since there is no /archive size/ header for cpio, the scripts have
to parse headers of each file in uncompressed ones.

The original tool works well when the uncompressed archives contain a few
files. But it gets really slow when there are lots. For example, initrd of
ubuntu 22.04.4 contains two uncompressed cpio, each holding a single file (amd
and intel microcode). Both tools are quick:

#+begin_example
  > time ./unmkinitramfs -s initrd/ubuntu-22.04.4 _
  0 77312
  77312 7208960
  7286272

  real    0m0.234s
  user    0m0.314s
  sys 0m0.105s

  > time ./unmkinitramfs-turbo -s initrd/ubuntu-22.04.4 _
  0 77312
  77312 7208960
  7286272

  real    0m0.096s
  user    0m0.107s
  sys 0m0.026s
#+end_example

In initrd of ubuntu 23.10.1 there is one extra uncompressed archive, containing
kernel modules and firmware files, 1985 files overall. This time the story is
different:

#+begin_example
  > time ./unmkinitramfs -s initrd/ubuntu-23.10.1 _
  0 77312
  77312 7200768
  7278080 78615040
  85893120

  real    0m15.453s
  user    0m20.199s
  sys 0m6.260s

  > time ./unmkinitramfs-turbo -s initrd/ubuntu-23.10.1 _
  0 77312
  77312 7200768
  7278080 78615040
  85893120

  real    0m1.418s
  user    0m1.772s
  sys 0m0.512s
#+end_example

The turbo tool turns out to be an order of magnitude faster in this case.

* Performance boost explained

The original tool is limited to external tools to parse binary input data.

The turbo tool parses a hex dump of input data instead, with help of bash's
=read -N= to process data in chunks, all in a single pass.

* Why xxd, not od from coreutils

/In the following, we ignore any whitespaces in tools' output, e.g. "a b\nc" and
"abc" are considered equal./

First and foremost: =od= is slow.

To dump in hex one uses =od -txN ..= where =N= could be 1, 2, 4 and 8. =N=
greatly affects the speed, there is no reason to use any value below 8.

One could benchmark the performance with such command (the input file is the
initrd from ubuntu =22.04.4= desktop iso, the size is =137M=):

#+begin_example
  hyperfine 'xxd -p ubuntu-22.04.4' 'od -vAn -tx'{8,4,2,1}' ubuntu-22.04.4'
#+end_example

Sample run results:

| Command                       | Mean [s]       | Min [s] | Max [s] | Relative     |
|-------------------------------+----------------+---------+---------+--------------|
| `xxd -p ubuntu-22.04.4`       | 1.301 ± 0.003  |   1.298 |   1.307 | 1.00         |
| `od -vAn -tx8 ubuntu-22.04.4` | 3.553 ± 0.033  |   3.509 |   3.608 | 2.73 ± 0.03  |
| `od -vAn -tx4 ubuntu-22.04.4` | 6.394 ± 0.049  |   6.316 |   6.470 | 4.92 ± 0.04  |
| `od -vAn -tx2 ubuntu-22.04.4` | 12.035 ± 0.114 |  11.835 |  12.179 | 9.25 ± 0.09  |
| `od -vAn -tx1 ubuntu-22.04.4` | 23.053 ± 0.239 |  22.677 |  23.379 | 17.72 ± 0.19 |

The problem with =-txN, N>1= is =od= treats sequences of =N= bytes as a whole
and prints those in native byte order. Example for an =amd64= machine:

#+begin_example
  > echo -n 01234567 | od -vAn -tx4
   33323130 37363534
#+end_example

The correct order can be forced with ~--endian=big~ option:

#+begin_example
  > echo -n 01234567 | od -vAn -tx4 --endian=big
   30313233 34353637
#+end_example

But the option is a relatively new one, only [[https://github.com/coreutils/coreutils/commit/b370924c03adaef222859061c61be06fc30c9a3e][introduced]] in 2014. There is no
such option in still supported ubuntu 14.04. On older /little endian/ systems
one still can utilize the =-tx2= speed boost with help of =dd=:

#+begin_example
  > echo -n 0123 | dd conv=swab 2>/dev/null | od -vAn -tx2
   3031 3233
#+end_example

Back to the best case of ~-tx8 --endian=big~. It is still not a drop-in
replacement for =xxd -p=. When the data size is not a multiple of =N= and we use
=-txN, N>1=, it gets padded with zeroes:

#+begin_example
  > echo -n 01235 | od -vAn -tx4 --endian=big
   30313233 35000000
#+end_example

So to make a correct dump one must know the data size ahead and take it into
account. Such function wraps it up:

#+begin_example
  function xxdp_like_od() {
      size=$(stat -c%s "$1")
      (( residue = size % 8 ))

      {
          if (( residue )); then
              od -vAn -tx1 -N"$residue"
          fi

          if (( size > residue )); then
              od -vAn -tx8 --endian=big
          fi
      } <"$1"
  }
#+end_example

Sample run:

#+begin_example
  > head -c 27 /dev/zero >sample
  > xxdp_like_od sample
  00 00 00
    0000000000000000 0000000000000000
   0000000000000000
#+end_example

So, compared to =xxd=, =od= is slow and picky.
